{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6021989b",
   "metadata": {},
   "source": [
    "# Song Emotion Classification, Using Multinomial Naive Bayes, and TF feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18299c",
   "metadata": {},
   "source": [
    "By:\n",
    "\n",
    "Anak Agung Gede Ngurah Ananda Wirasena (2308561079)\n",
    "\n",
    "Akira Rian Satya Dhamma (2308561079)\n",
    "\n",
    "I Gede Abhijana Prayata Wistara (2308561142)\n",
    "\n",
    "Benedictus Albert Effendi (2308561055)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1de99",
   "metadata": {},
   "source": [
    "## 1. Import Libraries yang Digunakan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8734e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from deep_translator import GoogleTranslator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386cd4d",
   "metadata": {},
   "source": [
    "## 2. Definisikan Parameter Global yang Akan Digunakan, serta Loading Dataset Utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726f6b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>full</th>\n",
       "      <th>reff</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Augmented Title - bahagia 1</td>\n",
       "      <td>Augmented Artist</td>\n",
       "      <td>lihat getirnya melewatkanmu na statusnya peluk...</td>\n",
       "      <td>menggapai lamar manja putih sekuntum maksud se...</td>\n",
       "      <td>bahagia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Augmented Title - marah 1</td>\n",
       "      <td>Augmented Artist</td>\n",
       "      <td>realita berpisah sedihmu pergilah lukamu time ...</td>\n",
       "      <td>kusesali puaskah takkan gombalan ukir famili y...</td>\n",
       "      <td>marah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Augmented Title - marah 2</td>\n",
       "      <td>Augmented Artist</td>\n",
       "      <td>kulawan gigi serigala asap bermain silau harap...</td>\n",
       "      <td>palsu januari menunggu you kemari bantu he tol...</td>\n",
       "      <td>marah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Augmented Title - marah 3</td>\n",
       "      <td>Augmented Artist</td>\n",
       "      <td>wakil love terbangkan kebobolan kuhapus kuingi...</td>\n",
       "      <td>beralaskan segenggam menyingkirkan hantamlah m...</td>\n",
       "      <td>marah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Augmented Title - marah 4</td>\n",
       "      <td>Augmented Artist</td>\n",
       "      <td>percintaan maksudmu sombongnya hempas runtuh k...</td>\n",
       "      <td>obi dipundak come keinginanmu kumpulan every p...</td>\n",
       "      <td>marah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title            artist  \\\n",
       "0  Augmented Title - bahagia 1  Augmented Artist   \n",
       "1    Augmented Title - marah 1  Augmented Artist   \n",
       "2    Augmented Title - marah 2  Augmented Artist   \n",
       "3    Augmented Title - marah 3  Augmented Artist   \n",
       "4    Augmented Title - marah 4  Augmented Artist   \n",
       "\n",
       "                                                full  \\\n",
       "0  lihat getirnya melewatkanmu na statusnya peluk...   \n",
       "1  realita berpisah sedihmu pergilah lukamu time ...   \n",
       "2  kulawan gigi serigala asap bermain silau harap...   \n",
       "3  wakil love terbangkan kebobolan kuhapus kuingi...   \n",
       "4  percintaan maksudmu sombongnya hempas runtuh k...   \n",
       "\n",
       "                                                reff  emotion  \n",
       "0  menggapai lamar manja putih sekuntum maksud se...  bahagia  \n",
       "1  kusesali puaskah takkan gombalan ukir famili y...    marah  \n",
       "2  palsu januari menunggu you kemari bantu he tol...    marah  \n",
       "3  beralaskan segenggam menyingkirkan hantamlah m...    marah  \n",
       "4  obi dipundak come keinginanmu kumpulan every p...    marah  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempTargetFilename =  ['./data/indo-song-emot.csv', './data/augmented.csv']\n",
    "targetFilename = tempTargetFilename[0]\n",
    "\n",
    "resultFilename = ['./data/train-data.csv', './data/test-data.csv'] # Index 0 untuk train, 1 untuk test\n",
    "\n",
    "# dataSplit = [0.7, 0.3] # Bisa memilih pembagian data 80%-20% atau 70%-30%\n",
    "dataSplit = [0.8, 0.2] \n",
    "fold = 10 # Banyak fold untuk k-fold cross validation\n",
    "emotion_label = ['bahagia', 'sedih', 'marah', 'takut']\n",
    "\n",
    "# translator = GoogleTranslator(source='id', target='en')\n",
    "\n",
    "base_dataset = pd.read_csv('./data/augmented.csv', index_col=0) #mengambil csv menjadi pandas, dan mendefinisikan kolom pertama sebagai index\n",
    "column_csvs = base_dataset.columns.tolist() # simpen nama kolom untuk training dan testing nanti\n",
    "base_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba48bef",
   "metadata": {},
   "source": [
    "## 3. Persiapan k-Fold Cross Validation, dan Fungsi Pembagian Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b9c3f",
   "metadata": {},
   "source": [
    "### 3.1 Definisi Fungsi Pembagian Data, yakni calcFold()\n",
    "Fungsi ini memastikan pembagian dari data terdistribusi secara seimbang (as possible), untuk tiap fold nantinya  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc2f5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFold(pdSeries):\n",
    "    global fold\n",
    "    newSeries = pd.Series(dtype=object)\n",
    "\n",
    "    for idx, value in pdSeries.items():\n",
    "        tempList = [int(value / fold)] * fold\n",
    "        tempRemainder = value % fold\n",
    "\n",
    "        for i in range(tempRemainder):\n",
    "            tempList[-(i + 1)] += 1\n",
    "\n",
    "        newSeries.loc[idx] = tempList\n",
    "\n",
    "    return newSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d52373",
   "metadata": {},
   "source": [
    "### 3.2 Menghitung Distribusi dari Tiap Label Emosi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "264f6bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "sedih      151\n",
      "bahagia    131\n",
      "marah       52\n",
      "takut       38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "<========After Folding==========>\n",
      "sedih      [15, 15, 15, 15, 15, 15, 15, 15, 15, 16]\n",
      "bahagia    [13, 13, 13, 13, 13, 13, 13, 13, 13, 14]\n",
      "marah                [5, 5, 5, 5, 5, 5, 5, 5, 6, 6]\n",
      "takut                [3, 3, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "labels_count = base_dataset['emotion'].value_counts()\n",
    "print(labels_count)\n",
    "\n",
    "print(\"\\n<========After Folding==========>\")\n",
    "foldedLabels = calcFold(labels_count)\n",
    "print(foldedLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299266db",
   "metadata": {},
   "source": [
    "### 3.3 Membagi Data Sesuai Kalkulasi Distribusinya, untuk Tiap Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb660974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Augmented Title - bahagia 1, Augmented Artist...</td>\n",
       "      <td>[Augmented Title - takut 4, Augmented Artist, ...</td>\n",
       "      <td>[galang rambu anarki, iwan fals, galang rambu ...</td>\n",
       "      <td>[bunga citra lestari, kecewa, sedikit waktu ya...</td>\n",
       "      <td>[langit abu-abu, tulus, tak mungkin secepat it...</td>\n",
       "      <td>[lelaki pencemburu, dewa19, detak di setiap de...</td>\n",
       "      <td>[tetap dalam jiwa, isyana sarasvati, tak perna...</td>\n",
       "      <td>[sandaran hati, letto, yakinkah kuberdiri. dia...</td>\n",
       "      <td>[selow, cover by via vallen, sudah biasa. diri...</td>\n",
       "      <td>[kukira kau rumah, amigdala, kau datang tidak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Augmented Title - marah 1, Augmented Artist, ...</td>\n",
       "      <td>[Augmented Title - takut 5, Augmented Artist, ...</td>\n",
       "      <td>[lantas, juicy luicy, lima hari sudah kurindu....</td>\n",
       "      <td>[hivi!, orang ke 3, saat berjumpa dan kau meny...</td>\n",
       "      <td>[cinta, naura ayu, bergetar hatiku saat kuberk...</td>\n",
       "      <td>[365, tiara andini, tiga ratus enam puluh lima...</td>\n",
       "      <td>[ kulakukan semua untukmu, ran, hanya denganmu...</td>\n",
       "      <td>[bukan superstar, project pop, andai aku pasha...</td>\n",
       "      <td>[sang dewi, lyodra, walaupun jiwaku pernah ter...</td>\n",
       "      <td>[maafkan aku, tiara andini, aku telah tahu kit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Augmented Title - marah 2, Augmented Artist, ...</td>\n",
       "      <td>[pergilah kasih, chrisye, tak pernah kusangka ...</td>\n",
       "      <td>[jatuh suka, tulus, sungguh aku tidak memiliki...</td>\n",
       "      <td>[afgan, jodoh pasti bertemu, andai engkau tahu...</td>\n",
       "      <td>[harta berharga, bunga citra lestari, harta ya...</td>\n",
       "      <td>[menjadi dia, tiara andini, aku ingat waktu ka...</td>\n",
       "      <td>[heavy rotation, jkt, satu.dua.tiga.empat . ak...</td>\n",
       "      <td>[sahabat selamanya, padi, dua tiga kapal belay...</td>\n",
       "      <td>[pikiran dan perjalanan, barasuara, di pikiran...</td>\n",
       "      <td>[dengan caraku, arsy widianto, brisia jodie, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Augmented Title - marah 3, Augmented Artist, ...</td>\n",
       "      <td>[dia milikku, yovie &amp; nuno, semula aku tidak t...</td>\n",
       "      <td>[bicara, monita tahalea, sudah berapa lama aku...</td>\n",
       "      <td>[gac, bahagia, hai hai apa kabar kawan. siapka...</td>\n",
       "      <td>[pasti bisa, citra scholastika, mentari terben...</td>\n",
       "      <td>[aku yang salah, nuca x mahalini, aku tidak me...</td>\n",
       "      <td>[kamu, coboy junior, kamu buat aku tersipu. bu...</td>\n",
       "      <td>[terlatih patah hati, the rain ft. endank soek...</td>\n",
       "      <td>[konon katanya, kunto aji, kau tidak pernah be...</td>\n",
       "      <td>[nyaman, andmesh, lama sudah aku menanti. bany...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Augmented Title - marah 4, Augmented Artist, ...</td>\n",
       "      <td>[bertaut, nadin amizah, bun hidup berjalan sep...</td>\n",
       "      <td>[remaja, hivi, kita remaja yang sedang dimabuk...</td>\n",
       "      <td>[duka, last child, kau membunuhku dengan keped...</td>\n",
       "      <td>[teman bahagia, jazz, takkan pernah terlintas....</td>\n",
       "      <td>[pesan terakhir, lyodra, telah aku coba terus ...</td>\n",
       "      <td>[status palsu, vidi aldiano, separuh hati deng...</td>\n",
       "      <td>[buka semangat baru, ello, barry, ipank, lala ...</td>\n",
       "      <td>[selamat (selamat tinggal), virgoun, audy, di ...</td>\n",
       "      <td>[laskar pelangi, nidji, mimpi adalah kunci. un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [Augmented Title - bahagia 1, Augmented Artist...   \n",
       "1  [Augmented Title - marah 1, Augmented Artist, ...   \n",
       "2  [Augmented Title - marah 2, Augmented Artist, ...   \n",
       "3  [Augmented Title - marah 3, Augmented Artist, ...   \n",
       "4  [Augmented Title - marah 4, Augmented Artist, ...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [Augmented Title - takut 4, Augmented Artist, ...   \n",
       "1  [Augmented Title - takut 5, Augmented Artist, ...   \n",
       "2  [pergilah kasih, chrisye, tak pernah kusangka ...   \n",
       "3  [dia milikku, yovie & nuno, semula aku tidak t...   \n",
       "4  [bertaut, nadin amizah, bun hidup berjalan sep...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  [galang rambu anarki, iwan fals, galang rambu ...   \n",
       "1  [lantas, juicy luicy, lima hari sudah kurindu....   \n",
       "2  [jatuh suka, tulus, sungguh aku tidak memiliki...   \n",
       "3  [bicara, monita tahalea, sudah berapa lama aku...   \n",
       "4  [remaja, hivi, kita remaja yang sedang dimabuk...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  [bunga citra lestari, kecewa, sedikit waktu ya...   \n",
       "1  [hivi!, orang ke 3, saat berjumpa dan kau meny...   \n",
       "2  [afgan, jodoh pasti bertemu, andai engkau tahu...   \n",
       "3  [gac, bahagia, hai hai apa kabar kawan. siapka...   \n",
       "4  [duka, last child, kau membunuhku dengan keped...   \n",
       "\n",
       "                                                   4  \\\n",
       "0  [langit abu-abu, tulus, tak mungkin secepat it...   \n",
       "1  [cinta, naura ayu, bergetar hatiku saat kuberk...   \n",
       "2  [harta berharga, bunga citra lestari, harta ya...   \n",
       "3  [pasti bisa, citra scholastika, mentari terben...   \n",
       "4  [teman bahagia, jazz, takkan pernah terlintas....   \n",
       "\n",
       "                                                   5  \\\n",
       "0  [lelaki pencemburu, dewa19, detak di setiap de...   \n",
       "1  [365, tiara andini, tiga ratus enam puluh lima...   \n",
       "2  [menjadi dia, tiara andini, aku ingat waktu ka...   \n",
       "3  [aku yang salah, nuca x mahalini, aku tidak me...   \n",
       "4  [pesan terakhir, lyodra, telah aku coba terus ...   \n",
       "\n",
       "                                                   6  \\\n",
       "0  [tetap dalam jiwa, isyana sarasvati, tak perna...   \n",
       "1  [ kulakukan semua untukmu, ran, hanya denganmu...   \n",
       "2  [heavy rotation, jkt, satu.dua.tiga.empat . ak...   \n",
       "3  [kamu, coboy junior, kamu buat aku tersipu. bu...   \n",
       "4  [status palsu, vidi aldiano, separuh hati deng...   \n",
       "\n",
       "                                                   7  \\\n",
       "0  [sandaran hati, letto, yakinkah kuberdiri. dia...   \n",
       "1  [bukan superstar, project pop, andai aku pasha...   \n",
       "2  [sahabat selamanya, padi, dua tiga kapal belay...   \n",
       "3  [terlatih patah hati, the rain ft. endank soek...   \n",
       "4  [buka semangat baru, ello, barry, ipank, lala ...   \n",
       "\n",
       "                                                   8  \\\n",
       "0  [selow, cover by via vallen, sudah biasa. diri...   \n",
       "1  [sang dewi, lyodra, walaupun jiwaku pernah ter...   \n",
       "2  [pikiran dan perjalanan, barasuara, di pikiran...   \n",
       "3  [konon katanya, kunto aji, kau tidak pernah be...   \n",
       "4  [selamat (selamat tinggal), virgoun, audy, di ...   \n",
       "\n",
       "                                                   9  \n",
       "0  [kukira kau rumah, amigdala, kau datang tidak ...  \n",
       "1  [maafkan aku, tiara andini, aku telah tahu kit...  \n",
       "2  [dengan caraku, arsy widianto, brisia jodie, t...  \n",
       "3  [nyaman, andmesh, lama sudah aku menanti. bany...  \n",
       "4  [laskar pelangi, nidji, mimpi adalah kunci. un...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldedList = defaultdict(list) # Dictionary dengan struktur {fold: [list for tiap row data]}, untuk menyimpan masing-masing fold\n",
    "foldPointer = {emotion: 0 for emotion in emotion_label} # Pointer untuk membantu assign row data tertentu pada fold yang belum \"penuh\"\n",
    "\n",
    "for idx, data in base_dataset.iterrows(): # data is a pd.Series\n",
    "    emot = data['emotion']\n",
    "    fPE = foldPointer[emot] #variabel untuk menyimpan nilai yang relevan agar tidak dipanggil setiap kali dibutuhan\n",
    "    \n",
    "    # append row data ke dictionary penyimpan fold\n",
    "    foldedList[fPE].append(list(data.values))\n",
    "    \n",
    "    # decrement untuk pencatatan\n",
    "    foldedLabels[emot][fPE] -= 1\n",
    "    \n",
    "    # ketika list pada indeks tertentu sudah mencapai 0, artinya telah memenuhi pembagian pada fold tersebut, jadi akan increment pointernya pada emosi tersebut\n",
    "    if foldedLabels[emot][fPE] == 0:\n",
    "        if foldPointer[emot] < fold -1: # mencegah index out of bound\n",
    "            foldPointer[emot] += 1\n",
    "\n",
    "# keperluan display\n",
    "foldedList_display_dict = {k: v[:5] for k, v in foldedList.items()} # mengambil 5 indeks pertama saja dari masing-masing fold\n",
    "foldedListDF_display = pd.DataFrame(dict(foldedList_display_dict))\n",
    "foldedListDF_display.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882cbac8",
   "metadata": {},
   "source": [
    "## 4. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd2c698",
   "metadata": {},
   "source": [
    "### 4.1 Inisialisasi Stopword\n",
    "Menggunakan beberapa kata tambahan berdasarkan eksplorasi data, serta beberapa kata dari berbagai sumber (githup repo, artikel, dan libray nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6045810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meyakinkan', 'seolah-olah', 'memperkirakan', 'apakah', 'mampu', 'masa', 'meskipun', 'berkata', 'dahulu', 'apatah', 'lanjutnya', 'juga', 'pasti', 'bung', 'disebutkan', 'mengucapkan', 'sepertinya', 'berbagai', 'inikah', 'sendirinya', 'mendatangi', 'tandasnya', 'sinilah', 'diketahuinya', 'pun', 'semata-mata', 'terjadilah', 'hm', 'semasa', 'tetapi', 'diibaratkan', 'ditunjukkannya', 'berkehendak', 'serta', 'ditunjuknya', 'minta', 'lagi', 'dimintai', 'lebih', 'tegasnya', 'tadi', 'mengingat', 'akankah', 'dimulailah', 'kedua', 'maupun', 'tandas', 'tutur', 'ditambahkan', 'demikian', 'tiba-tiba', 'lamanya', 'segala', 'apabila', 'jelasnya', 'berikutnya', 'menyiapkan', 'sering', 'meyakini', 'ujarnya', 'ibu', 'beginikah', 'jelaslah', 'diketahui', 'sekiranya', 'keadaan', 'sebagian', 'sedikitnya', 'siapakah', 'seenaknya', 'mengucapkannya', 'segera', 'maka', 'mengerjakan', 'lima', 'mampukah', 'dua', 'merupakan', 'hendaklah', 'sedang', 'oleh', 'semula', 'memulai', 'sekali', 'berada', 'dikatakannya', 'jawab', 'menyeluruh', 'woho', 'saling', 'pernah', 'boleh', 'mengatakannya', 'menanti-nanti', 'sebisanya', 'bersama-sama', 'tadinya', 'bermaksud', 'terdahulu', 'sebagaimana', 'kitalah', 'bapak', 'mengatakan', 'jauh', 'oh', 'terdiri', 'bulan', 'entah', 'punya', 'tetap', 'bertanya-tanya', 'berakhirlah', 'pukul', 'amatlah', 'ditanyakan', 'jelas', 'keduanya', 'berjumlah', 'misalkan', 'ucap', 'berakhirnya', 'berakhir', 'terlihat', 'sana', 'berawal', 'kami', 'dipersoalkan', 'dimaksudnya', 'mungkinkah', 'memperlihatkan', 'dapat', 'secukupnya', 'sesuatu', 'amat', 'asal', 'begini', 'ibaratkan', 'itu', 'macam', 'diperlukannya', 'ternyata', 'andalah', 'seseorang', 'dimaksud', 'setelah', 'tengah', 'mulailah', 'mengungkapkan', 'bagai', 'agaknya', 'dipunyai', 'setengah', 'diminta', 'sepihak', 'saat', 'dimungkinkan', 'mempunyai', 'sudah', 'dimisalkan', 'selalu', 'diakhirinya', 'tentang', 'menantikan', 'dijelaskannya', 'wo', 'selagi', 'hanyalah', 'bermula', 'menunjuk', 'sebegini', 'sama', 'kalaupun', 'memberikan', 'ditujukan', 'datang', 'jangankan', 'terdapat', 'sementara', 'setidak-tidaknya', 'keseluruhannya', 'suatu', 'lanjut', 'sendiri', 'wong', 'awalnya', 'seketika', 'kemungkinan', 'hendaknya', 'sesudahnya', 'ujar', 'menanya', 'tiba', 'sajalah', 'ikut', 'bersama', 'dimaksudkannya', 'nyaris', 'keterlaluan', 'mengibaratkan', 'padanya', 'sekarang', 'tanya', 'dikira', 'dipastikan', 'terhadapnya', 'kepadanya', 'keinginan', 'terbanyak', 'sangatlah', 'yakin', 'manalagi', 'menanyai', 'sekaligus', 'mulai', 'inginkah', 'melainkan', 'menegaskan', 'se', 'diinginkan', 'termasuk', 'kita', 'dong', 'dalam', 'semuanya', 'ditegaskan', 'sudahkah', 'berapapun', 'kok', 'misal', 'tegas', 'persoalan', 'perlu', 'hendak', 'setempat', 'belumlah', 'ibarat', 'hari', 'lewat', 'menurut', 'berturut', 'sesudah', 'ia', 'kata', 'didatangkan', 'setinggi', 'melakukan', 'sempat', 'disinilah', 'mula', 'menjelaskan', 'sekitarnya', 'sewaktu', 'sebesar', 'diibaratkannya', 'kamilah', 'dini', 'dimulainya', 'sekitar', 'terutama', 'sejenak', 'terasa', 'sejauh', 'per', 'pada', 'nanti', 'menjawab', 'lain', 'adanya', 'jawabnya', 'bekerja', 'bermacam', 'sendirian', 'kamulah', 'asalkan', 'dia', 'bertutur', 'rasa', 'mempergunakan', 'menaiki', 'menanti', 'bukan', 'mungkin', 'bakalan', 'antara', 'pertanyaan', 'tambah', 'selain', 'walau', 'tentulah', 'diri', 'seberapa', 'kiranya', 'secara', 'jumlah', 'bukankah', 'ingat-ingat', 'mempersiapkan', 'beri', 'makin', 'menjadi', 'jikalau', 'bisakah', 'mendatang', 'antar', 'mengakhiri', 'mengapa', 'tanpa', 'menandaskan', 'janganlah', 'jawaban', 'uh', 'dari', 'tertentu', 'biasanya', 'cukupkah', 'di', 'lagian', 'diucapkannya', 'semampu', 'menunjuknya', 'toh', 'agar', 'selanjutnya', 'sedangkan', 'satu', 'bilakah', 'misalnya', 'teringat', 'kini', 'sebaik-baiknya', 'sejak', 'seterusnya', 'tempat', 'tak', 'sesampai', 'berapa', 'saya', 'awal', 'ditanyai', 'pula', 'agak', 'nah', 'kemungkinannya', 'waktu', 'sebuah', 'tinggi', 'semacam', 'semisalnya', 'kan', 'balik', 'walaupun', 'tahun', 'tentu', 'depan', 'setiba', 'bagaimana', 'dipergunakan', 'tambahnya', 'dekat', 'ataukah', 'pantas', 'tiap', 'dimaksudkan', 'apa', 'memintakan', 'katakanlah', 'semaunya', 'bisa', 'sekalian', 'adapun', 'terkira', 'diakhiri', 'disampaikan', 'kira-kira', 'bakal', 'dibuat', 'besar', 'dan', 'sambil', 'dialah', 'ditanya', 'baik', 'dilalui', 'yakni', 'membuat', 'diucapkan', 'akhir', 'pihaknya', 'bagi', 'meski', 'serupa', 'disebut', 'pertama-tama', 'tersebutlah', 'berturut-turut', 'telah', 'kira', 'seperlunya', 'yaitu', 'begitulah', 'keluar', 'ucapnya', 'hanya', 'ialah', 'katakan', 'ungkapnya', 'bahwa', 'khususnya', 'demikianlah', 'jangan', 'umum', 'katanya', 'kesampaian', 'ini', 'sebaik', 'tahu', 'sedemikian', 'menginginkan', 'ada', 'sekadarnya', 'nyatanya', 'terlebih', 'menyampaikan', 'pihak', 'ke', 'sampai', 'kelihatan', 'seringnya', 'hal', 'enggaknya', 'itukah', 'menyangkut', 'jumlahnya', 'kapankah', 'terhadap', 'beginilah', 'sampaikan', 'berlebihan', 'mulanya', 'mengenai', 'tunjuk', 'kalau', 'para', 'mendapatkan', 'menunjukkan', 'hampir', 'kembali', 'setidaknya', 'seingat', 'mirip', 'cara', 'ah', 'pastilah', 'mengira', 'kinilah', 'tertuju', 'mana', 'sebab', 'teringat-ingat', 'berdatangan', 'mendapat', 'menggunakan', 'seharusnya', 'waduh', 'empat', 'setibanya', 'siapapun', 'pak', 'selama', 'memihak', 'sebagainya', 'usai', 'dipertanyakan', 'akan', 'begitukah', 'berlangsung', 'bawah', 'gunakan', 'kelima', 'dengan', 'sebenarnya', 'kau', 'akulah', 'terakhir', 'nya', 'memerlukan', 'memungkinkan', 'ingin', 'waktunya', 'ingat', 'diungkapkan', 'siapa', 'sekalipun', 'sekecil', 'masalahnya', 'sesama', 'jadi', 'bolehlah', 'bersiap', 'kemudian', 'merasa', 'dikarenakan', 'tapi', 'nantinya', 'sekurangnya', 'terjadi', 'atas', 'berikut', 'daripada', 'sepantasnyalah', 'sehingga', 'siap', 'keseluruhan', 'bukannya', 'melihat', 'mengibaratkannya', 'ketika', 'anda', 'percuma', 'sesaat', 'menuturkan', 'terjadinya', 'sebut', 'tentunya', 'artinya', 'menunjuki', 'soal', 'bagaimanakah', 'bahwasanya', 'cuma', 'selamanya', 'mendatangkan', 'akhiri', 'ditunjukkan', 'bukanlah', 'mempertanyakan', 'sebegitu', 'sekadar', 'yang', 'diingatkan', 'seorang', 'menambahkan', 'antaranya', 'kala', 'sampai-sampai', 'perlunya', 'semasih', 'ataupun', 'kelamaan', 'tepat', 'bertanya', 'karena', 'kecil', 'terus', 'harus', 'kamu', 'bolehkah', 'biasa', 'jadinya', 'masalah', 'sela', 'kelihatannya', 'hingga', 'betulkah', 'bersiap-siap', 'haruslah', 'belakang', 'paling', 'ungkap', 'saatnya', 'adalah', 'berapakah', 'kapan', 'lalu', 'rata', 'digunakan', 'dilihat', 'akhirnya', 'caranya', 'makanya', 'menuju', 'buat', 'diperbuatnya', 'sama-sama', 'sebutnya', 'ra', 'menanyakan', 'ta', 'semata', 'mempersoalkan', 'sesegera', 'jadilah', 'malahan', 'perlukah', 'mengingatkan', 'diantaranya', 'wahai', 'bahkan', 'begitu', 'diantara', 'semampunya', 'mengetahui', 'kurang', 'dirinya', 'diperlukan', 'dijawab', 'sebabnya', 'inginkan', 'memang', 'turut', 'bermacam-macam', 'ibaratnya', 'jelaskan', 'sepantasnya', 'usah', 'tis', 'belakangan', 'diperkirakan', 'masing-masing', 'memisalkan', 'wah', 'berikan', 'dilakukan', 'melalui', 'pertanyakan', 'semua', 'penting', 'memperbuat', 'berupa', 'tampak', 'menghendaki', 'diberi', 'masing', 'sekali-kali', 'dulu', 'benar', 'sebutlah', 'menyatakan', 'jika', 'itulah', 'panjang', 'baru', 'berlalu', 'ho', 'sebaliknya', 'melihatnya', 'disebutkannya', 'manakala', 'diberikannya', 'kasus', 'dituturkan', 'tersampaikan', 'betul', 'olehnya', 'kebetulan', 'sejumlah', 'seluruhnya', 'demi', 'sebanyak', 'aku', 'sedikit', 'tidak', 'umumnya', 'apalagi', 'sesuatunya', 'kepada', 'banyak', 'untuk', 'bagian', 'benarkah', 'pentingnya', 'tuturnya', 'harusnya', 'sepanjang', 'soalnya', 'tidaklah', 'atau', 'tidakkah', 'dituturkannya', 'pertama', 'ran', 'tersebut', 'segalanya', 'sebaiknya', 'seperti', 'sayalah', 'disini', 'belum', 'rasanya', 'lama', 'seolah', 'diberikan', 'mereka', 'malah', 'seusai', 'terlalu', 'sesekali', 'dikatakan', 'guna', 'diingat', 'kapanpun', 'luar', 'berkeinginan', 'sebelum', 'bagaikan', 'berarti', 'sudahlah', 'mau', 'berlainan', 'berapalah', 'semisal', 'lainnya', 'sebetulnya', 'masih', 'benarlah', 'beberapa', 'begitupun', 'berkenaan', 'diperbuat', 'beginian', 'sangat', 'ditunjuki', 'kalaulah', 'tanyakan', 'naik', 'setiap', 'tampaknya', 'seluruh', 'sebelumnya', 'merekalah', 'namun', 'meminta', 'dibuatnya', 'tanyanya', 'sekurang-kurangnya', 'semakin', 'dikerjakan', 'apaan', 'bagaimanapun', 'cukuplah', 'ditunjuk', 'lah', 'padahal', 'berujar', 'memberi', 'dijelaskan', 'masihkah', 'justru', 'cukup', 'rupanya', 'selaku', 'inilah', 'kenapa', 'menyebutkan', 'entahlah', 'enggak', 'ditandaskan', 'tiga', 'karenanya', 'sebagai', 'didapat', 'selama-lamanya', 'supaya', 'berkali-kali', 'dimulai', 'diperlihatkan', 'bila', 'kalian', 'sini', 'saja', 'memastikan'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "predef = [\"kau\",\"ra\",\"ran\",\"ta\",\"wo\",\"uh\",\"ah\",\"oh\",\"ho\",\"woho\",\"hm\",\"nya\",\"tis\",\"ada\",\"adalah\",\"adanya\",\"adapun\",\"agak\",\"agaknya\",\"agar\",\"akan\",\"akankah\",\"akhir\",\"akhiri\",\"akhirnya\",\"aku\",\"akulah\",\"amat\",\"amatlah\",\"anda\",\"andalah\",\"antar\",\"antara\",\"antaranya\",\"apa\",\"apaan\",\"apabila\",\"apakah\",\"apalagi\",\"apatah\",\"artinya\",\"asal\",\"asalkan\",\"atas\",\"atau\",\"ataukah\",\"ataupun\",\"awal\",\"awalnya\",\"bagai\",\"bagaikan\",\"bagaimana\",\"bagaimanakah\",\"bagaimanapun\",\"bagi\",\"bagian\",\"bahkan\",\"bahwa\",\"bahwasanya\",\"baik\",\"bakal\",\"bakalan\",\"balik\",\"banyak\",\"bapak\",\"baru\",\"bawah\",\"beberapa\",\"begini\",\"beginian\",\"beginikah\",\"beginilah\",\"begitu\",\"begitukah\",\"begitulah\",\"begitupun\",\"bekerja\",\"belakang\",\"belakangan\",\"belum\",\"belumlah\",\"benar\",\"benarkah\",\"benarlah\",\"berada\",\"berakhir\",\"berakhirlah\",\"berakhirnya\",\"berapa\",\"berapakah\",\"berapalah\",\"berapapun\",\"berarti\",\"berawal\",\"berbagai\",\"berdatangan\",\"beri\",\"berikan\",\"berikut\",\"berikutnya\",\"berjumlah\",\"berkali-kali\",\"berkata\",\"berkehendak\",\"berkeinginan\",\"berkenaan\",\"berlainan\",\"berlalu\",\"berlangsung\",\"berlebihan\",\"bermacam\",\"bermacam-macam\",\"bermaksud\",\"bermula\",\"bersama\",\"bersama-sama\",\"bersiap\",\"bersiap-siap\",\"bertanya\",\"bertanya-tanya\",\"berturut\",\"berturut-turut\",\"bertutur\",\"berujar\",\"berupa\",\"besar\",\"betul\",\"betulkah\",\"biasa\",\"biasanya\",\"bila\",\"bilakah\",\"bisa\",\"bisakah\",\"boleh\",\"bolehkah\",\"bolehlah\",\"buat\",\"bukan\",\"bukankah\",\"bukanlah\",\"bukannya\",\"bulan\",\"bung\",\"cara\",\"caranya\",\"cukup\",\"cukupkah\",\"cukuplah\",\"cuma\",\"dahulu\",\"dalam\",\"dan\",\"dapat\",\"dari\",\"daripada\",\"datang\",\"dekat\",\"demi\",\"demikian\",\"demikianlah\",\"dengan\",\"depan\",\"di\",\"dia\",\"diakhiri\",\"diakhirinya\",\"dialah\",\"diantara\",\"diantaranya\",\"diberi\",\"diberikan\",\"diberikannya\",\"dibuat\",\"dibuatnya\",\"didapat\",\"didatangkan\",\"digunakan\",\"diibaratkan\",\"diibaratkannya\",\"diingat\",\"diingatkan\",\"diinginkan\",\"dijawab\",\"dijelaskan\",\"dijelaskannya\",\"dikarenakan\",\"dikatakan\",\"dikatakannya\",\"dikerjakan\",\"diketahui\",\"diketahuinya\",\"dikira\",\"dilakukan\",\"dilalui\",\"dilihat\",\"dimaksud\",\"dimaksudkan\",\"dimaksudkannya\",\"dimaksudnya\",\"diminta\",\"dimintai\",\"dimisalkan\",\"dimulai\",\"dimulailah\",\"dimulainya\",\"dimungkinkan\",\"dini\",\"dipastikan\",\"diperbuat\",\"diperbuatnya\",\"dipergunakan\",\"diperkirakan\",\"diperlihatkan\",\"diperlukan\",\"diperlukannya\",\"dipersoalkan\",\"dipertanyakan\",\"dipunyai\",\"diri\",\"dirinya\",\"disampaikan\",\"disebut\",\"disebutkan\",\"disebutkannya\",\"disini\",\"disinilah\",\"ditambahkan\",\"ditandaskan\",\"ditanya\",\"ditanyai\",\"ditanyakan\",\"ditegaskan\",\"ditujukan\",\"ditunjuk\",\"ditunjuki\",\"ditunjukkan\",\"ditunjukkannya\",\"ditunjuknya\",\"dituturkan\",\"dituturkannya\",\"diucapkan\",\"diucapkannya\",\"diungkapkan\",\"dong\",\"dua\",\"dulu\",\"empat\",\"enggak\",\"enggaknya\",\"entah\",\"entahlah\",\"guna\",\"gunakan\",\"hal\",\"hampir\",\"hanya\",\"hanyalah\",\"hari\",\"harus\",\"haruslah\",\"harusnya\",\"hendak\",\"hendaklah\",\"hendaknya\",\"hingga\",\"ia\",\"ialah\",\"ibarat\",\"ibaratkan\",\"ibaratnya\",\"ibu\",\"ikut\",\"ingat\",\"ingat-ingat\",\"ingin\",\"inginkah\",\"inginkan\",\"ini\",\"inikah\",\"inilah\",\"itu\",\"itukah\",\"itulah\",\"jadi\",\"jadilah\",\"jadinya\",\"jangan\",\"jangankan\",\"janganlah\",\"jauh\",\"jawab\",\"jawaban\",\"jawabnya\",\"jelas\",\"jelaskan\",\"jelaslah\",\"jelasnya\",\"jika\",\"jikalau\",\"juga\",\"jumlah\",\"jumlahnya\",\"justru\",\"kala\",\"kalau\",\"kalaulah\",\"kalaupun\",\"kalian\",\"kami\",\"kamilah\",\"kamu\",\"kamulah\",\"kan\",\"kapan\",\"kapankah\",\"kapanpun\",\"karena\",\"karenanya\",\"kasus\",\"kata\",\"katakan\",\"katakanlah\",\"katanya\",\"ke\",\"keadaan\",\"kebetulan\",\"kecil\",\"kedua\",\"keduanya\",\"keinginan\",\"kelamaan\",\"kelihatan\",\"kelihatannya\",\"kelima\",\"keluar\",\"kembali\",\"kemudian\",\"kemungkinan\",\"kemungkinannya\",\"kenapa\",\"kepada\",\"kepadanya\",\"kesampaian\",\"keseluruhan\",\"keseluruhannya\",\"keterlaluan\",\"ketika\",\"khususnya\",\"kini\",\"kinilah\",\"kira\",\"kira-kira\",\"kiranya\",\"kita\",\"kitalah\",\"kok\",\"kurang\",\"lagi\",\"lagian\",\"lah\",\"lain\",\"lainnya\",\"lalu\",\"lama\",\"lamanya\",\"lanjut\",\"lanjutnya\",\"lebih\",\"lewat\",\"lima\",\"luar\",\"macam\",\"maka\",\"makanya\",\"makin\",\"malah\",\"malahan\",\"mampu\",\"mampukah\",\"mana\",\"manakala\",\"manalagi\",\"masa\",\"masalah\",\"masalahnya\",\"masih\",\"masihkah\",\"masing\",\"masing-masing\",\"mau\",\"maupun\",\"melainkan\",\"melakukan\",\"melalui\",\"melihat\",\"melihatnya\",\"memang\",\"memastikan\",\"memberi\",\"memberikan\",\"membuat\",\"memerlukan\",\"memihak\",\"meminta\",\"memintakan\",\"memisalkan\",\"memperbuat\",\"mempergunakan\",\"memperkirakan\",\"memperlihatkan\",\"mempersiapkan\",\"mempersoalkan\",\"mempertanyakan\",\"mempunyai\",\"memulai\",\"memungkinkan\",\"menaiki\",\"menambahkan\",\"menandaskan\",\"menanti\",\"menanti-nanti\",\"menantikan\",\"menanya\",\"menanyai\",\"menanyakan\",\"mendapat\",\"mendapatkan\",\"mendatang\",\"mendatangi\",\"mendatangkan\",\"menegaskan\",\"mengakhiri\",\"mengapa\",\"mengatakan\",\"mengatakannya\",\"mengenai\",\"mengerjakan\",\"mengetahui\",\"menggunakan\",\"menghendaki\",\"mengibaratkan\",\"mengibaratkannya\",\"mengingat\",\"mengingatkan\",\"menginginkan\",\"mengira\",\"mengucapkan\",\"mengucapkannya\",\"mengungkapkan\",\"menjadi\",\"menjawab\",\"menjelaskan\",\"menuju\",\"menunjuk\",\"menunjuki\",\"menunjukkan\",\"menunjuknya\",\"menurut\",\"menuturkan\",\"menyampaikan\",\"menyangkut\",\"menyatakan\",\"menyebutkan\",\"menyeluruh\",\"menyiapkan\",\"merasa\",\"mereka\",\"merekalah\",\"merupakan\",\"meski\",\"meskipun\",\"meyakini\",\"meyakinkan\",\"minta\",\"mirip\",\"misal\",\"misalkan\",\"misalnya\",\"mula\",\"mulai\",\"mulailah\",\"mulanya\",\"mungkin\",\"mungkinkah\",\"nah\",\"naik\",\"namun\",\"nanti\",\"nantinya\",\"nyaris\",\"nyatanya\",\"oleh\",\"olehnya\",\"pada\",\"padahal\",\"padanya\",\"pak\",\"paling\",\"panjang\",\"pantas\",\"para\",\"pasti\",\"pastilah\",\"penting\",\"pentingnya\",\"per\",\"percuma\",\"perlu\",\"perlukah\",\"perlunya\",\"pernah\",\"persoalan\",\"pertama\",\"pertama-tama\",\"pertanyaan\",\"pertanyakan\",\"pihak\",\"pihaknya\",\"pukul\",\"pula\",\"pun\",\"punya\",\"rasa\",\"rasanya\",\"rata\",\"rupanya\",\"saat\",\"saatnya\",\"saja\",\"sajalah\",\"saling\",\"sama\",\"sama-sama\",\"sambil\",\"sampai\",\"sampai-sampai\",\"sampaikan\",\"sana\",\"sangat\",\"sangatlah\",\"satu\",\"saya\",\"sayalah\",\"se\",\"sebab\",\"sebabnya\",\"sebagai\",\"sebagaimana\",\"sebagainya\",\"sebagian\",\"sebaik\",\"sebaik-baiknya\",\"sebaiknya\",\"sebaliknya\",\"sebanyak\",\"sebegini\",\"sebegitu\",\"sebelum\",\"sebelumnya\",\"sebenarnya\",\"seberapa\",\"sebesar\",\"sebetulnya\",\"sebisanya\",\"sebuah\",\"sebut\",\"sebutlah\",\"sebutnya\",\"secara\",\"secukupnya\",\"sedang\",\"sedangkan\",\"sedemikian\",\"sedikit\",\"sedikitnya\",\"seenaknya\",\"segala\",\"segalanya\",\"segera\",\"seharusnya\",\"sehingga\",\"seingat\",\"sejak\",\"sejauh\",\"sejenak\",\"sejumlah\",\"sekadar\",\"sekadarnya\",\"sekali\",\"sekali-kali\",\"sekalian\",\"sekaligus\",\"sekalipun\",\"sekarang\",\"sekecil\",\"seketika\",\"sekiranya\",\"sekitar\",\"sekitarnya\",\"sekurang-kurangnya\",\"sekurangnya\",\"sela\",\"selagi\",\"selain\",\"selaku\",\"selalu\",\"selama\",\"selama-lamanya\",\"selamanya\",\"selanjutnya\",\"seluruh\",\"seluruhnya\",\"semacam\",\"semakin\",\"semampu\",\"semampunya\",\"semasa\",\"semasih\",\"semata\",\"semata-mata\",\"semaunya\",\"sementara\",\"semisal\",\"semisalnya\",\"sempat\",\"semua\",\"semuanya\",\"semula\",\"sendiri\",\"sendirian\",\"sendirinya\",\"seolah\",\"seolah-olah\",\"seorang\",\"sepanjang\",\"sepantasnya\",\"sepantasnyalah\",\"seperlunya\",\"seperti\",\"sepertinya\",\"sepihak\",\"sering\",\"seringnya\",\"serta\",\"serupa\",\"sesaat\",\"sesama\",\"sesampai\",\"sesegera\",\"sesekali\",\"seseorang\",\"sesuatu\",\"sesuatunya\",\"sesudah\",\"sesudahnya\",\"setelah\",\"setempat\",\"setengah\",\"seterusnya\",\"setiap\",\"setiba\",\"setibanya\",\"setidak-tidaknya\",\"setidaknya\",\"setinggi\",\"seusai\",\"sewaktu\",\"siap\",\"siapa\",\"siapakah\",\"siapapun\",\"sini\",\"sinilah\",\"soal\",\"soalnya\",\"suatu\",\"sudah\",\"sudahkah\",\"sudahlah\",\"supaya\",\"tadi\",\"tadinya\",\"tahu\",\"tahun\",\"tak\",\"tambah\",\"tambahnya\",\"tampak\",\"tampaknya\",\"tandas\",\"tandasnya\",\"tanpa\",\"tanya\",\"tanyakan\",\"tanyanya\",\"tapi\",\"tegas\",\"tegasnya\",\"telah\",\"tempat\",\"tengah\",\"tentang\",\"tentu\",\"tentulah\",\"tentunya\",\"tepat\",\"terakhir\",\"terasa\",\"terbanyak\",\"terdahulu\",\"terdapat\",\"terdiri\",\"terhadap\",\"terhadapnya\",\"teringat\",\"teringat-ingat\",\"terjadi\",\"terjadilah\",\"terjadinya\",\"terkira\",\"terlalu\",\"terlebih\",\"terlihat\",\"termasuk\",\"ternyata\",\"tersampaikan\",\"tersebut\",\"tersebutlah\",\"tertentu\",\"tertuju\",\"terus\",\"terutama\",\"tetap\",\"tetapi\",\"tiap\",\"tiba\",\"tiba-tiba\",\"tidak\",\"tidakkah\",\"tidaklah\",\"tiga\",\"tinggi\",\"toh\",\"tunjuk\",\"turut\",\"tutur\",\"tuturnya\",\"ucap\",\"ucapnya\",\"ujar\",\"ujarnya\",\"umum\",\"umumnya\",\"ungkap\",\"ungkapnya\",\"untuk\",\"usah\",\"usai\",\"waduh\",\"wah\",\"wahai\",\"waktu\",\"waktunya\",\"walau\",\"walaupun\",\"wong\",\"yaitu\",\"yakin\",\"yakni\",\"yang\",\"di\",\"ke\",\"dari\",\"dan\",\"yang\"]\n",
    "\n",
    "stopWords = set(stopwords.words('indonesian'))\n",
    "stopWords.update(set(predef))\n",
    "# stopWords.update(set(nuStopWordFromAnalysis))\n",
    "\n",
    "print(stopWords)\n",
    "\n",
    "det_word = {'ku', 'kau', 'mu', '',}\n",
    "\n",
    "\n",
    "\n",
    "# whole_corpus = sorted(whole_corpus)\n",
    "\n",
    "# print(whole_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73434fe",
   "metadata": {},
   "source": [
    "### 4.2. Definisikan Fungsi Helper Preprocessing \n",
    "Yakni sebagai berikut:\n",
    "- `reduceWords`: Menyderhanakan kata-kata ekspresif yang sering muncul pada lirik lagu (e.g., \"asmaraaaa\" >> \"asmara\").\n",
    "- `removeStopWords`: Menghilangkan stopword yang telah diinisialisasi pada bagian sebelumnya.\n",
    "- `preProcess`: Pipeline utama dalam preprocessing, mulai dari cleaning(menghilangkan karakter non-alfanumerikal), tokenisasi, reduceWords(), dan removeStopWords(). (tambahan nanti untuk sinonim dengan terjemahan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cdbe84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anak', 'gembala']\n"
     ]
    }
   ],
   "source": [
    "def reduceWords(words):\n",
    "    def reduce(word):\n",
    "        while (True):\n",
    "            if(len(word) > 1):\n",
    "                if word[-1] == word[-2]: #ketika huruf di kedua indeks terakhir sama (e.g. rumaHH)\n",
    "                    word = word[:-1] #maka indeks terakhir akan dihapus\n",
    "                else:\n",
    "                    return word #jika sudah berbeda langsung direturn\n",
    "            else:\n",
    "                return word \n",
    "\n",
    "    newToken = []\n",
    "    for word in words:\n",
    "        reduced_word = reduce(str(word)) \n",
    "        if reduced_word: \n",
    "            newToken.append(reduced_word)\n",
    "\n",
    "    return newToken\n",
    "\n",
    "def removeStopWords(token):\n",
    "    global stopWords\n",
    "    return [tkn for tkn in token if tkn not in stopWords and tkn] # mengembalikan token yang tidak ada di set stopWords\n",
    "\n",
    "def preProcess(text):\n",
    "    pat = r'[^a-zA-Z0-9\\s]' # pattern untuk library re untuk menyisakan karakter alfanumerik saja (dengan spasi)\n",
    "\n",
    "    tokenz = str(text).lower() # memastikan setiap kata bukan huruf kapital, walaupun pada dataset asli sudah bersih, tetapi untuk implementasi ketika meminta input nantinya\n",
    "    tokenz = re.sub(pat, '', tokenz)  # apply aturan yang sudah diinisialisasi\n",
    "\n",
    "    # tokenz = stemmer.stem(tokenz)  # stemming saat ini hanya memperlambat dan merusak akurasi\n",
    "\n",
    "    tokenz = nltk.word_tokenize(tokenz)  # tokenisasi menggunakan library (lebih cepat)\n",
    "\n",
    "    tokenz = reduceWords(tokenz) \n",
    "\n",
    "    tokenz = removeStopWords(tokenz)\n",
    "\n",
    "    # print(\"Currently translating \" + str(len(tokenz)) + \" token\")\n",
    "    # tokenz = translator.translate_batch(tokenz)\n",
    "\n",
    "    return tokenz\n",
    "\n",
    "print(preProcess(\"AkU,, adalAHHH anak GeMBaLaAAaa~\")) #contoh implementasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c81ca6",
   "metadata": {},
   "source": [
    "## 5. Multinomial Naive Bayes (MNB) Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f2208",
   "metadata": {},
   "source": [
    "### 5.1 Inisialisasi Variabel yang Akan Digunakan, serta Fungsi Helper\n",
    "Fungsi Helper dengan penjelasan sebagai berikut:\n",
    "- `countFreq`: Menghitung banyaknya suatu term muncul per label, serta total term pada tiap label.\n",
    "- `calcCP`: Menghitung conditional probability, dari term terkait emosi tertentu, dengan nilai smoothing terbaik (hypertuning).\n",
    "- `resetGlobals`: Mereset seluruh variabel global, agar bisa digunakan kembali untuk tiap fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00a4d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_given_label_full = defaultdict(lambda: defaultdict(int))  # term frequency untuk 'full' dan 'reff'(dibawah) lirik berdasarkan label tertentu\n",
    "tf_given_label_reff = defaultdict(lambda: defaultdict(int))  # dict = {'term':{'label':tf}}\n",
    "\n",
    "number_of_term_at_a_label_full = defaultdict(int)  # total banyak term dari lirik pada label tertentu\n",
    "number_of_term_at_a_label_reff = defaultdict(int)  # dict = {'label':number of term}\n",
    "\n",
    "number_of_unique_term_across_label_full = 0  # banyaknya term unik dari seluruh label (seluruh dataset)\n",
    "number_of_unique_term_across_label_reff = 0\n",
    "\n",
    "label_frequency = defaultdict(int)  # frekuensi tiap label: dict = {'label':frequency}\n",
    "total_label_frequency = 0  # Total of frequency from label_frequency\n",
    "\n",
    "song_unique_term_full = set() # set dari seluruh term unik yang ada pada 'full' dan 'reff' lyric\n",
    "song_unique_term_reff = set() \n",
    "\n",
    "term_conditional_probability_at_label_full = defaultdict(lambda: defaultdict(float))\n",
    "term_conditional_probability_at_label_reff = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "def resetGlobals():\n",
    "    global tf_given_label_full, tf_given_label_reff\n",
    "    global number_of_term_at_a_label_full, number_of_term_at_a_label_reff\n",
    "    global number_of_unique_term_across_label_full, number_of_unique_term_across_label_reff\n",
    "    global label_frequency, total_label_frequency\n",
    "    global song_unique_term_full, song_unique_term_reff\n",
    "    global term_conditional_probability_at_label_full, term_conditional_probability_at_label_reff\n",
    "\n",
    "    tf_given_label_full = defaultdict(lambda: defaultdict(int))\n",
    "    tf_given_label_reff = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    number_of_term_at_a_label_full = defaultdict(int)\n",
    "    number_of_term_at_a_label_reff = defaultdict(int)\n",
    "\n",
    "    number_of_unique_term_across_label_full = 0\n",
    "    number_of_unique_term_across_label_reff = 0\n",
    "\n",
    "    label_frequency = defaultdict(int)\n",
    "    total_label_frequency = 0\n",
    "\n",
    "    song_unique_term_full = set()\n",
    "    song_unique_term_reff = set()\n",
    "\n",
    "    term_conditional_probability_at_label_full = defaultdict(lambda: defaultdict(float))\n",
    "    term_conditional_probability_at_label_reff = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "smoothing = 0.0096 # laplace smoothing alpha value (telah melalui hypertuning)\n",
    "\n",
    "\n",
    "def countFreq(emo, text, termFreq, termCount):\n",
    "    for word in text:\n",
    "        termFreq[emo][word] += 1 # mencari frekuensi kemunculan suatu term(word) pada tiap label(emo)\n",
    "        termCount[emo] += 1 # menyimpan banyaknya term pada label tertentu\n",
    "\n",
    "def calcCP(terms, local_emotion_labels, cpDict, tfOLabel, totalTerm, uniqTerm):\n",
    "    global smoothing\n",
    "    for term in terms:\n",
    "        for emo in local_emotion_labels:\n",
    "            # P(term|class) = (count(term,class) + alpha) / (count(all_terms_in_class) + alpha * V)\n",
    "            \n",
    "            numerator = tfOLabel[emo][term] + smoothing\n",
    "            denominator = totalTerm[emo] + (uniqTerm)\n",
    "            if denominator == 0: # menghindari pembagian dengan 0\n",
    "                cpDict[emo][term] = 0.0\n",
    "            else:\n",
    "                cpDict[emo][term] = numerator / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cada969",
   "metadata": {},
   "source": [
    "### 5.2. MNB Training Function (`train`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23a081d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global number_of_unique_term_across_label_full, number_of_unique_term_across_label_reff\n",
    "    global total_label_frequency\n",
    "    \n",
    "    train_df = pd.read_csv(resultFilename[0], encoding='utf-8')\n",
    "    print(f'Start training on {resultFilename[0]} with {len(train_df)} records.')\n",
    "\n",
    "    for index, row in train_df.iterrows():\n",
    "        full_lyrics = row['full']\n",
    "        reff_lyrics = row['reff']\n",
    "        emotion = row['emotion']\n",
    "\n",
    "        processed_full = preProcess(full_lyrics)\n",
    "        processed_reff = preProcess(reff_lyrics)\n",
    "        \n",
    "        countFreq(emotion, processed_full, tf_given_label_full, number_of_term_at_a_label_full)\n",
    "        countFreq(emotion, processed_reff, tf_given_label_reff, number_of_term_at_a_label_reff)\n",
    "\n",
    "        song_unique_term_full.update(set(processed_full))\n",
    "        song_unique_term_reff.update(set(processed_reff))\n",
    "\n",
    "        label_frequency[emotion] += 1\n",
    "\n",
    "    number_of_unique_term_across_label_full = len(song_unique_term_full)\n",
    "    number_of_unique_term_across_label_reff = len(song_unique_term_reff)\n",
    "\n",
    "    total_label_frequency = sum(label_frequency.values())\n",
    "    \n",
    "    if total_label_frequency == 0:\n",
    "        print(\"Warning: No training data seems to have been processed, or label_frequency is empty.\")\n",
    "        \n",
    "    calcCP(song_unique_term_full, emotion_label, term_conditional_probability_at_label_full, tf_given_label_full, number_of_term_at_a_label_full, number_of_unique_term_across_label_full)\n",
    "    calcCP(song_unique_term_reff, emotion_label, term_conditional_probability_at_label_reff, tf_given_label_reff, number_of_term_at_a_label_reff, number_of_unique_term_across_label_reff)\n",
    "    \n",
    "    print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622ade9",
   "metadata": {},
   "source": [
    "### 5.3. MNB Testing Function (`test`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec4d997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct_full_predictions = 0\n",
    "    correct_reff_predictions = 0\n",
    "    total_songs_tested = 0\n",
    "    \n",
    "    y_true_fold_list = []\n",
    "    y_pred_full_fold_list = []\n",
    "    y_pred_reff_fold_list = []\n",
    "    \n",
    "    test_df = pd.read_csv(resultFilename[1], encoding='utf-8')\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        total_songs_tested += 1\n",
    "        full_lyrics = row['full']\n",
    "        reff_lyrics = row['reff']\n",
    "        actual_emotion = row['emotion']\n",
    "        \n",
    "        y_true_fold_list.append(actual_emotion)\n",
    "\n",
    "        processed_full = preProcess(full_lyrics)\n",
    "        processed_reff = preProcess(reff_lyrics)\n",
    "\n",
    "        mnb_probabilities_full = defaultdict(float)\n",
    "        mnb_probabilities_reff = defaultdict(float)\n",
    "\n",
    "        current_song_terms_frequency_full = defaultdict(int)\n",
    "        for term in processed_full:\n",
    "            current_song_terms_frequency_full[term] += 1\n",
    "\n",
    "        current_song_terms_frequency_reff = defaultdict(int)\n",
    "        for term in processed_reff:\n",
    "            current_song_terms_frequency_reff[term] += 1\n",
    "\n",
    "        for current_emotion_candidate in emotion_label:\n",
    "            \n",
    "            class_count = label_frequency.get(current_emotion_candidate, 0)\n",
    "            \n",
    "            log_prior_prob = np.log(class_count) - np.log(total_label_frequency)\n",
    "            \n",
    "            log_likelihood_full = 0.0\n",
    "            for term, freq in current_song_terms_frequency_full.items():\n",
    "                term_prob = term_conditional_probability_at_label_full[current_emotion_candidate].get(term, 0.0)\n",
    "\n",
    "                if term_prob == 0.0: \n",
    "                    N_c_full = number_of_term_at_a_label_full.get(current_emotion_candidate, 0)\n",
    "                    V_full = number_of_unique_term_across_label_full\n",
    "                    \n",
    "                    denominator_full = N_c_full + (V_full * smoothing)\n",
    "                    if denominator_full > 0:\n",
    "                        term_prob = smoothing / denominator_full \n",
    "                    else:\n",
    "                        term_prob = 1e-100 \n",
    "                \n",
    "                log_likelihood_full += freq * np.log(term_prob)\n",
    "            mnb_probabilities_full[current_emotion_candidate] = log_prior_prob + log_likelihood_full\n",
    "\n",
    "            log_likelihood_reff = 0.0\n",
    "            for term, freq in current_song_terms_frequency_reff.items():\n",
    "                term_prob = term_conditional_probability_at_label_reff[current_emotion_candidate].get(term, 0.0)\n",
    "\n",
    "                if term_prob == 0.0:\n",
    "                    N_c_reff = number_of_term_at_a_label_reff.get(current_emotion_candidate, 0)\n",
    "                    V_reff = number_of_unique_term_across_label_reff\n",
    "                    \n",
    "                    denominator_reff = N_c_reff + (V_reff * smoothing)\n",
    "                    if denominator_reff > 0:\n",
    "                        term_prob = smoothing / denominator_reff\n",
    "                    else:\n",
    "                        term_prob = 1e-100\n",
    "                \n",
    "                log_likelihood_reff += freq * np.log(term_prob)\n",
    "            mnb_probabilities_reff[current_emotion_candidate] = log_prior_prob + log_likelihood_reff\n",
    "\n",
    "        predicted_emotion_full = \"\"\n",
    "        if mnb_probabilities_full: \n",
    "            if all(v == -np.inf for v in mnb_probabilities_full.values()):\n",
    "                predicted_emotion_full = emotion_label[0] if emotion_label else \"unknown\"\n",
    "            else:\n",
    "                predicted_emotion_full = max(mnb_probabilities_full, key=mnb_probabilities_full.get)\n",
    "        else: \n",
    "            predicted_emotion_full = emotion_label[0] if emotion_label else \"unknown\"\n",
    "        y_pred_full_fold_list.append(predicted_emotion_full)\n",
    "        if predicted_emotion_full == actual_emotion:\n",
    "            correct_full_predictions += 1\n",
    "\n",
    "        predicted_emotion_reff = \"\"\n",
    "        if mnb_probabilities_reff:\n",
    "            if all(v == -np.inf for v in mnb_probabilities_reff.values()):\n",
    "                predicted_emotion_reff = emotion_label[0] if emotion_label else \"unknown\"\n",
    "            else:\n",
    "                predicted_emotion_reff = max(mnb_probabilities_reff, key=mnb_probabilities_reff.get)\n",
    "        else: \n",
    "            predicted_emotion_reff = emotion_label[0] if emotion_label else \"unknown\"\n",
    "        y_pred_reff_fold_list.append(predicted_emotion_reff)\n",
    "        if predicted_emotion_reff == actual_emotion:\n",
    "            correct_reff_predictions += 1\n",
    "\n",
    "    print(f\"Testing finished. Full Correct: {correct_full_predictions}, Reff Correct: {correct_reff_predictions}, Total Tested: {total_songs_tested}\")\n",
    "    return correct_full_predictions, correct_reff_predictions, total_songs_tested, y_true_fold_list, y_pred_full_fold_list, y_pred_reff_fold_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425c1e4",
   "metadata": {},
   "source": [
    "### 5.4. Custom Metrics Calculation Function\n",
    "This function calculates per-emotion precision, recall, F1-score, and support, along with overall accuracy, without relying on scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44cef706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_display_metrics(y_true_list, y_pred_list, labels, model_name=\"Model\"):\n",
    "    metrics_data = []\n",
    "    if not y_true_list or not y_pred_list: # Handle empty lists\n",
    "        print(f\"No data to calculate metrics for {model_name}.\")\n",
    "        return pd.DataFrame(), 0.0\n",
    "        \n",
    "    for emotion in labels:\n",
    "        tp = 0 # True Positives\n",
    "        fp = 0 # False Positives\n",
    "        fn = 0 # False Negatives\n",
    "        # tn = 0 # True Negatives (less direct for multi-class, focusing on per-class P, R, F1)\n",
    "\n",
    "        for true_label, pred_label in zip(y_true_list, y_pred_list):\n",
    "            if true_label == emotion and pred_label == emotion:\n",
    "                tp += 1\n",
    "            elif true_label != emotion and pred_label == emotion:\n",
    "                fp += 1\n",
    "            elif true_label == emotion and pred_label != emotion:\n",
    "                fn += 1\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        support = y_true_list.count(emotion)\n",
    "\n",
    "        metrics_data.append({\n",
    "            'Emotion': emotion,\n",
    "            'Precision': f\"{precision:.2f}\",\n",
    "            'Recall': f\"{recall:.2f}\",\n",
    "            'F1-Score': f\"{f1_score:.2f}\",\n",
    "            'Support (True)': support,\n",
    "            'TP': tp,\n",
    "            'FP': fp,\n",
    "            'FN': fn\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    print(f\"\\n<======== Detailed Metrics for {model_name} (Aggregated) =========>\")\n",
    "    print(metrics_df.to_string())\n",
    "\n",
    "    correct_predictions = 0\n",
    "    for i in range(len(y_true_list)):\n",
    "        if y_true_list[i] == y_pred_list[i]:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    overall_accuracy = correct_predictions / len(y_true_list) if len(y_true_list) > 0 else 0.0\n",
    "    print(f\"\\nOverall {model_name} Accuracy: {overall_accuracy*100:.2f}% (based on {len(y_true_list)} predictions)\")\n",
    "    return metrics_df, overall_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202520d9",
   "metadata": {},
   "source": [
    "## 6. K-Fold Cross-Validation Execution\n",
    "Melakukan K-fold cross-validation. Di setiap iterasi (fold):\n",
    "1. Beberapa fold akan dijadikan test set (sesuai `num_test_folds`), dan sisanya (K - `num_test_folds`) akan digabung menjadi training set.\n",
    "2. Set ini akan dikonversi menjadi Pandas DataFrame dan disimpan sebagai `test-data.csv` dan `train-data.csv`.\n",
    "3. Variabel global MNB direset.\n",
    "4. Model di-train menggunakan `train()` (membaca `train-data.csv`).\n",
    "5. Model dievaluasi menggunakan `test()` (membaca `test-data.csv`).\n",
    "6. Skor akurasi dan prediksi diakumulasi.\n",
    "\n",
    "Akhirnya, rata-rata akurasi dan metrik per-emosi akan ditampilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845faa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total initial data divisions (k_initial): 10\n",
      "Number of divisions for testing in each iteration: 2\n",
      "Number of divisions for training in each iteration: 8\n",
      "This will result in approximately a 80% / 20% train/test split per iteration.\n",
      "\n",
      "Iteration 1/10\n",
      "Start training on ./data/train-data.csv with 300 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 48, Reff Correct: 36, Total Tested: 72\n",
      "Iteration 1 Accuracy (Full): 66.67%\n",
      "Iteration 1 Accuracy (Reff): 50.00%\n",
      "\n",
      "Iteration 2/10\n",
      "Start training on ./data/train-data.csv with 299 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 62, Reff Correct: 42, Total Tested: 73\n",
      "Iteration 2 Accuracy (Full): 84.93%\n",
      "Iteration 2 Accuracy (Reff): 57.53%\n",
      "\n",
      "Iteration 3/10\n",
      "Start training on ./data/train-data.csv with 298 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 70, Reff Correct: 49, Total Tested: 74\n",
      "Iteration 3 Accuracy (Full): 94.59%\n",
      "Iteration 3 Accuracy (Reff): 66.22%\n",
      "\n",
      "Iteration 4/10\n",
      "Start training on ./data/train-data.csv with 298 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 65, Reff Correct: 53, Total Tested: 74\n",
      "Iteration 4 Accuracy (Full): 87.84%\n",
      "Iteration 4 Accuracy (Reff): 71.62%\n",
      "\n",
      "Iteration 5/10\n",
      "Start training on ./data/train-data.csv with 298 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 61, Reff Correct: 47, Total Tested: 74\n",
      "Iteration 5 Accuracy (Full): 82.43%\n",
      "Iteration 5 Accuracy (Reff): 63.51%\n",
      "\n",
      "Iteration 6/10\n",
      "Start training on ./data/train-data.csv with 298 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 68, Reff Correct: 49, Total Tested: 74\n",
      "Iteration 6 Accuracy (Full): 91.89%\n",
      "Iteration 6 Accuracy (Reff): 66.22%\n",
      "\n",
      "Iteration 7/10\n",
      "Start training on ./data/train-data.csv with 298 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 71, Reff Correct: 50, Total Tested: 74\n",
      "Iteration 7 Accuracy (Full): 95.95%\n",
      "Iteration 7 Accuracy (Reff): 67.57%\n",
      "\n",
      "Iteration 8/10\n",
      "Start training on ./data/train-data.csv with 297 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 66, Reff Correct: 52, Total Tested: 75\n",
      "Iteration 8 Accuracy (Full): 88.00%\n",
      "Iteration 8 Accuracy (Reff): 69.33%\n",
      "\n",
      "Iteration 9/10\n",
      "Start training on ./data/train-data.csv with 294 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 51, Reff Correct: 46, Total Tested: 78\n",
      "Iteration 9 Accuracy (Full): 65.38%\n",
      "Iteration 9 Accuracy (Reff): 58.97%\n",
      "\n",
      "Iteration 10/10\n",
      "Start training on ./data/train-data.csv with 296 records.\n",
      "Training finished\n",
      "Testing finished. Full Correct: 46, Reff Correct: 36, Total Tested: 76\n",
      "Iteration 10 Accuracy (Full): 60.53%\n",
      "Iteration 10 Accuracy (Reff): 47.37%\n",
      "\n",
      "<======== Cross-Validation Summary (Aggregated over all iterations) =========>\n",
      "Average Accuracy (Full Lyrics): 81.72% (based on 744 total predictions)\n",
      "Average Accuracy (Reff Lyrics Only): 61.83% (based on 744 total predictions)\n",
      "\n",
      "<======== Detailed Metrics for Full Lyrics Model (Aggregated) =========>\n",
      "   Emotion Precision Recall F1-Score  Support (True)   TP  FP  FN\n",
      "0  bahagia      0.75   0.83     0.79             262  218  72  44\n",
      "1    sedih      0.82   0.78     0.80             302  235  51  67\n",
      "2    marah      0.94   0.88     0.91             104   91   6  13\n",
      "3    takut      0.90   0.84     0.87              76   64   7  12\n",
      "\n",
      "Overall Full Lyrics Model Accuracy: 81.72% (based on 744 predictions)\n",
      "\n",
      "<======== Detailed Metrics for Reff Lyrics Model (Aggregated) =========>\n",
      "   Emotion Precision Recall F1-Score  Support (True)   TP   FP   FN\n",
      "0  bahagia      0.62   0.61     0.61             262  159   98  103\n",
      "1    sedih      0.60   0.59     0.60             302  179  120  123\n",
      "2    marah      0.69   0.63     0.66             104   66   29   38\n",
      "3    takut      0.60   0.74     0.66              76   56   37   20\n",
      "\n",
      "Overall Reff Lyrics Model Accuracy: 61.83% (based on 744 predictions)\n",
      "\n",
      "<======== Original Calculation Method (for comparison based on fixed avg test len) =========>\n",
      "Rata-rata kebenaran label (Full - orig calc base): 60.80 lagu penuh\n",
      "Persentase keakuratan model (Full - based on avg correct per iteration vs avg tested per iteration): 81.72%\n",
      "\n",
      "Rata-rata kebenaran label (Reff - orig calc base): 46.00 reff\n",
      "Persentase keakuratan model (Reff - based on avg correct per iteration vs avg tested per iteration): 61.83%\n"
     ]
    }
   ],
   "source": [
    "total_correct_full_overall = 0\n",
    "total_correct_reff_overall = 0\n",
    "total_samples_processed_overall = 0\n",
    "\n",
    "overall_y_true = []\n",
    "overall_y_pred_full = []\n",
    "overall_y_pred_reff = []\n",
    "\n",
    "num_test_folds = int(fold * dataSplit[1]) \n",
    "\n",
    "if num_test_folds >= fold:\n",
    "    raise ValueError(\"num_test_folds must be less than the total number of initial divisions (fold variable).\")\n",
    "if num_test_folds <= 0:\n",
    "    raise ValueError(\"num_test_folds must be at least 1.\")\n",
    "\n",
    "num_train_folds = fold - num_test_folds\n",
    "print(f\"Total initial data divisions (k_initial): {fold}\")\n",
    "print(f\"Number of divisions for testing in each iteration: {num_test_folds}\")\n",
    "print(f\"Number of divisions for training in each iteration: {num_train_folds}\")\n",
    "print(f\"This will result in approximately a {num_train_folds*100/fold:.0f}% / {num_test_folds*100/fold:.0f}% train/test split per iteration.\")\n",
    "\n",
    "for i in range(fold): \n",
    "    print(f\"\\nIteration {i+1}/{fold}\")\n",
    "    \n",
    "    train_data_for_current_iteration = []\n",
    "    test_data_for_current_iteration = []\n",
    "\n",
    "    current_test_fold_indices = []\n",
    "    for j in range(num_test_folds):\n",
    "        current_test_fold_indices.append((i + j) % fold)\n",
    "\n",
    "    current_train_fold_indices = []\n",
    "    for k_idx in range(fold):\n",
    "        if k_idx not in current_test_fold_indices:\n",
    "            current_train_fold_indices.append(k_idx)\n",
    "\n",
    "    for fold_idx in current_test_fold_indices:\n",
    "        if fold_idx in foldedList:\n",
    "            test_data_for_current_iteration.extend(foldedList[fold_idx])\n",
    "\n",
    "    for fold_idx in current_train_fold_indices:\n",
    "        if fold_idx in foldedList:\n",
    "            train_data_for_current_iteration.extend(foldedList[fold_idx])\n",
    "    \n",
    "    if train_data_for_current_iteration:\n",
    "        train_df_current = pd.DataFrame(train_data_for_current_iteration, columns=column_csvs)\n",
    "        train_df_current.to_csv(resultFilename[0], index=False, encoding='utf-8') \n",
    "    else:\n",
    "        pd.DataFrame(columns=column_csvs).to_csv(resultFilename[0], index=False, encoding='utf-8')\n",
    "\n",
    "    if test_data_for_current_iteration:\n",
    "        test_df_current = pd.DataFrame(test_data_for_current_iteration, columns=column_csvs)\n",
    "        test_df_current.to_csv(resultFilename[1], index=False, encoding='utf-8') \n",
    "    else:\n",
    "        pd.DataFrame(columns=column_csvs).to_csv(resultFilename[1], index=False, encoding='utf-8')\n",
    "\n",
    "    resetGlobals() \n",
    "\n",
    "    if train_data_for_current_iteration: \n",
    "        train()\n",
    "\n",
    "    iter_correct_full, iter_correct_reff, iter_total_tested = 0, 0, 0\n",
    "    iter_y_true, iter_y_pred_full, iter_y_pred_reff = [], [], []\n",
    "\n",
    "    if test_data_for_current_iteration: \n",
    "        if train_data_for_current_iteration : \n",
    "            iter_correct_full, iter_correct_reff, iter_total_tested, iter_y_true, iter_y_pred_full, iter_y_pred_reff = test()\n",
    "            \n",
    "            overall_y_true.extend(iter_y_true)\n",
    "            overall_y_pred_full.extend(iter_y_pred_full)\n",
    "            overall_y_pred_reff.extend(iter_y_pred_reff)\n",
    "\n",
    "    total_correct_full_overall += iter_correct_full\n",
    "    total_correct_reff_overall += iter_correct_reff\n",
    "    total_samples_processed_overall += iter_total_tested\n",
    "    \n",
    "    if iter_total_tested > 0:\n",
    "        print(f\"Iteration {i+1} Accuracy (Full): {iter_correct_full/iter_total_tested*100:.2f}%\")\n",
    "        print(f\"Iteration {i+1} Accuracy (Reff): {iter_correct_reff/iter_total_tested*100:.2f}%\")\n",
    "\n",
    "print(\"\\n<======== Cross-Validation Summary (Aggregated over all iterations) =========>\")\n",
    "if total_samples_processed_overall > 0:\n",
    "    calculate_and_display_metrics(overall_y_true, overall_y_pred_full, emotion_label, model_name=\"Full Lyrics Model\")\n",
    "    calculate_and_display_metrics(overall_y_true, overall_y_pred_reff, emotion_label, model_name=\"Reff Lyrics Model\")\n",
    "else:\n",
    "    print(\"No samples were processed across all iterations. Cannot calculate average accuracy or metrics.\")\n",
    "\n",
    "if fold > 0 and total_samples_processed_overall > 0:\n",
    "    print(\"\\n<======== Original Calculation Method (for comparison based on fixed avg test len) =========>\")\n",
    "    avg_correct_full_orig_calc_base = total_correct_full_overall / fold \n",
    "    print(f\"Rata-rata kebenaran label (Full - orig calc base): {avg_correct_full_orig_calc_base:.2f} lagu penuh\")\n",
    "\n",
    "    avg_correct_reff_orig_calc_base = total_correct_reff_overall / fold\n",
    "    print(f\"Rata-rata kebenaran label (Reff - orig calc base): {avg_correct_reff_orig_calc_base:.2f} reff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Function untuk Prediksi Berbasis Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sedih', defaultdict(<class 'float'>, {'bahagia': np.float64(-481.3825823888632), 'sedih': np.float64(-391.240593598259), 'marah': np.float64(-526.9746566187333), 'takut': np.float64(-563.7782222149358)}), ['takut', 'marah', 'bahagia', 'sedih'])\n",
      "Prediction From Most Confident to Least:\n"
     ]
    }
   ],
   "source": [
    "def testLy(lyrics):\n",
    "    lyr_token = preProcess(lyrics)\n",
    "\n",
    "    mnb_prob = defaultdict(float)\n",
    "    current_song_term_frequency = defaultdict(int)\n",
    "\n",
    "    for term in lyr_token:\n",
    "        current_song_term_frequency[term] += 1\n",
    "\n",
    "    for current_emotion_candidate in emotion_label:\n",
    "        log_prior_prob = np.log(label_frequency[current_emotion_candidate]) - np.log(total_label_frequency)\n",
    "        \n",
    "        log_likelihood = 0.0\n",
    "        for term, freq in current_song_term_frequency.items():\n",
    "            term_prob = term_conditional_probability_at_label_full[current_emotion_candidate].get(term, 0.0)\n",
    "            if term_prob > 0:\n",
    "                log_likelihood += freq * np.log(term_prob)\n",
    "            else:\n",
    "                denominator = (number_of_term_at_a_label_full.get(current_emotion_candidate, 0) + (number_of_unique_term_across_label_full * smoothing))\n",
    "                if denominator > 0:\n",
    "                    smoothed_unseen_prob = smoothing / denominator\n",
    "                    if smoothed_unseen_prob > 0:\n",
    "                        log_likelihood += freq * np.log(smoothed_unseen_prob)\n",
    "                    else:\n",
    "                        log_likelihood += -np.inf\n",
    "                else:\n",
    "                    log_likelihood += -np.inf\n",
    "        mnb_prob[current_emotion_candidate] = log_prior_prob + log_likelihood\n",
    "\n",
    "    probsNames = []\n",
    "    for key in mnb_prob:\n",
    "        probsNames.append(key)\n",
    "\n",
    "    probsNames.sort(key = mnb_prob.get)\n",
    "\n",
    "    predicted_emotion = max(mnb_prob, key=mnb_prob.get)\n",
    "    return predicted_emotion, mnb_prob, probsNames\n",
    "\n",
    "lirik_bos = \"Berat bebanku Meninggalkanmu Separuh nafas jiwaku sirna Bukan salahmu Apa dayaku Mungkin benar cinta sejati tak berpihak pada kita Kasihku Sampai disini kisah kita Jangan tangisi keadaannya Bukan karena kita berbeda Dengarkan Dengarkan lagu lagu ini Melodi rintihan hati ini Kisah kita Berakhir di Januari Selamat tinggal kisah sejatiku Wow pergilah Kasihku Sampai disini kisah kita Jangan tangisi keadaannya Bukan karena kita berbeda Dengarkan lagu lagu ini Melodi rintihan hati ini Kisah kita berakhir di januari Dengarkan lagu lagu ini Melodi rintihan hati ini Kisah kita berakhir Berakhir Berakhir di januari Berakhir di januari\"\n",
    "\n",
    "result, probabilities, sorted = testLy(lirik_bos)\n",
    "print(testLy(lirik_bos))\n",
    "print(\"Prediction From Most Confident to Least:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
